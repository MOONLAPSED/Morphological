services:
  anythingllm:
    image: mintplexlabs/anythingllm
    container_name: anythingllm
    ports:
      - "3001:3001"
    cap_add:
      - SYS_ADMIN
    environment:
      - STORAGE_DIR=/app/server/storage
      - ENV_SECRET=${ENV_SECRET}
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_PATH=http://host.docker.internal:11434  # Use host.docker.internal to access the host
      - OLLAMA_MODEL_PREF=gemma2:latest
      - OLLAMA_MODEL_TOKEN_LIMIT=8192
      - EMBEDDING_ENGINE=ollama
      - EMBEDDING_BASE_PATH=http://host.docker.internal:11434
      - EMBEDDING_MODEL_PREF=nomic-embed-text:latest
      - EMBEDDING_MODEL_MAX_CHUNK_LENGTH=16384
      - VECTOR_DB=lancedb
      # Add any other keys here for services or settings
    volumes:
      - anythingllm_storage:/app/server/storage
      - ./local_storage:/docs/rfc/
    restart: always

volumes:
  anythingllm_storage:
    driver: local